{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa1e797-89b3-477d-919c-9e717a5a15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from peft) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from peft) (2.5.1)\n",
      "Collecting tqdm (from peft)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting safetensors (from peft)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting huggingface_hub>=0.25.0 (from peft)\n",
      "  Downloading huggingface_hub-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from transformers) (3.17.0)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.25.0->peft)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch>=1.13.0->peft) (72.1.0)\n",
      "Collecting sympy==1.13.1 (from torch>=1.13.0->peft)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.0 MB 1.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.0/12.0 MB 2.1 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 2.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.1/12.0 MB 2.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.9/12.0 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.7/12.0 MB 2.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.7/12.0 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.5/12.0 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/12.0 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.3/12.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.7/12.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.4/12.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.2/12.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.7/12.0 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 3.5 MB/s  0:00:03\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 2.4 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.7 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.8/2.7 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 2.8 MB/s  0:00:00\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.2 MB 1.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.8/6.2 MB 1.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.3/6.2 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.1/6.2 MB 1.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.4/6.2 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.9/6.2 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 3.4/6.2 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.7/6.2 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.2/6.2 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.7/6.2 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 1.7 MB/s  0:00:03\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, sympy, safetensors, regex, fsspec, huggingface_hub, tokenizers, accelerate, transformers, peft\n",
      "\n",
      "  Attempting uninstall: sympy\n",
      "\n",
      "    Found existing installation: sympy 1.14.0\n",
      "\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "    Uninstalling sympy-1.14.0:\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   -------- -------------------------------  2/10 [safetensors]\n",
      "   ---------------- -----------------------  4/10 [fsspec]\n",
      "   ---------------- -----------------------  4/10 [fsspec]\n",
      "   -------------------- -------------------  5/10 [huggingface_hub]\n",
      "   -------------------- -------------------  5/10 [huggingface_hub]\n",
      "   -------------------- -------------------  5/10 [huggingface_hub]\n",
      "   -------------------- -------------------  5/10 [huggingface_hub]\n",
      "   -------------------- -------------------  5/10 [huggingface_hub]\n",
      "   ---------------------------- -----------  7/10 [accelerate]\n",
      "   ---------------------------- -----------  7/10 [accelerate]\n",
      "   ---------------------------- -----------  7/10 [accelerate]\n",
      "   ---------------------------- -----------  7/10 [accelerate]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   ------------------------------------ ---  9/10 [peft]\n",
      "   ------------------------------------ ---  9/10 [peft]\n",
      "   ------------------------------------ ---  9/10 [peft]\n",
      "   ------------------------------------ ---  9/10 [peft]\n",
      "   ------------------------------------ ---  9/10 [peft]\n",
      "   ---------------------------------------- 10/10 [peft]\n",
      "\n",
      "Successfully installed accelerate-1.11.0 fsspec-2025.10.0 huggingface_hub-0.36.0 peft-0.17.1 regex-2025.11.3 safetensors-0.6.2 sympy-1.13.1 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install peft transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51117f82-af16-44e9-970d-a5f7ecd4151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.48.2-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.3 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from bitsandbytes) (2.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from bitsandbytes) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.2)\n",
      "Using cached bitsandbytes-0.48.2-py3-none-win_amd64.whl (59.0 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.48.2\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf8de6a-1b70-4cbf-b7c9-ecf0e79a9734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (0.48.2)\n",
      "Requirement already satisfied: torch<3,>=2.3 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from bitsandbytes) (2.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from bitsandbytes) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chama\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699cfc43-3865-4606-a7d4-d697afdb041a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "C:\\Users\\chama\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\transformers\\quantizers\\auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "  \"Agents/LLM/safefelora_lora_adapters\",\n",
    "  load_in_4bit = True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Agents/LLM/safefelora_lora_adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7923e10-d823-4e58-8fae-133afac082fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Answer the following question.\n",
      "\n",
      "### Input:\n",
      "Tell me about yourself. Name, age etc\n",
      "\n",
      "### Response:\n",
      "My name is John, I'm 30 years old.\n"
     ]
    }
   ],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "{response}\"\"\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        instruction=\"Answer the following question .\",\n",
    "        input=(\"Tell me about yourself. Name, age etc\"),\n",
    "        response=\"\",\n",
    "    )\n",
    "], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=1000, temperature=0.7, top_p=0.9)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ff288-2dd6-4ada-8368-0fa61ae23055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef441bdf-8914-46a1-bf57-938a5e310dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
